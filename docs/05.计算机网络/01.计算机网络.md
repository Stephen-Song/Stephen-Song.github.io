---
title: 计算机网络
date: 2021-11-24 15:31:36
permalink: /pages/2448f7/
---
## 常见的HTTP请求方法

- `get` 向服务器获取数据

- `post` 将实体提交给指定的资源，通常造成服务器资源修改

- `put`上传文件，更新数据
- `delete` 删除服务器上面的对象

- `head` 获取报文首部，与`get`相比不返回报文主体部分
- `options`：询问支持的请求方法，用来跨域请求

- `connect` 要求在与代理服务器通信时建立隧道，使用隧道进行`tcp`通信
- `trace` 回显服务器收到的请求，主要用于测试或诊断

# HTTP协议

## `get`和`post`的区别

- **应用场景不同：**一般`get`请求用于服务器资源不会产生影响，比如请求一个网页的资源，但是`post`会对服务器产生影响，比如注册用户之类的
- **缓存不同：**浏览器一般会对`get`请求缓存，一般不会对`post`请求缓存

- **发送的报文格式不同：**`get`请求的报文实体为空，`post`请求的报文实体一般为向服务器发送的数据
- **安全性不同**：`get`将参数放在`url`的后面，post传递的参数不在`query`上面

- **请求长度：**浏览器对`url`的长度有限制，会影响`get`请求发送数据的长度
- `post`支持更多的数据类型的数据



## `post`和`put`的区别

- `put`向服务端发送数据，但不会增加数据的种类，无论进行多少次`put`，结果并没有什么不同(理解为更新数据)

- `post`向服务端发送请求，会改变数据的种类，可以理解为创建数据



## 常见的`content-type`有哪些

1. `application/x-www-form-urlencoded `按照`key=value&key=value`进行编码
2. `multipart/form-data` 通常用表单上传文件

1. `application/json` 服务器消息主体是序列化的JSON字符串
2. `text/xml` 主要提交xml格式数据



## `HTTP`状态码是`304`多好还是少好

状态码`304`是服务器为了提高网站访问速度，而对之前访问的页面指定缓存机制，当客户端对这些页面进行请求，服务端会判断内容是否和之前相同，如果相同客户端调用缓存内容

但是搜索引擎会更加青睐更新频率的网站，通过特定的时间对网站抓取返回的状态码来调节网站抓取频次，若一直是304，蜘蛛就会降低抓取次数，相反，若网站变化频率快，每次都能获取新内容，蜘蛛的回访率会变高


**<mark>产生304较多的原因：</mark>**

- 页面更新长或不更新
- 纯静态页面

**304过多问题**

- 网站快照停止
- 收录减少

- 搜索引擎权重下降



## 介绍一下`options`请求

`options`的用途主要有两个

- 获取服务器支持的所有`http`请求方法
- 用于检查访问权限，比如在进行`cors`跨域资源共享的时候，对于复杂请求，就是使用`options`方法发送嗅探请求，判断是否有权限访问指定的资源

## `http1.0`和`http1.1`之间有哪些区别

- **连接方面**：`http1.0`默认支持非持久连接，而`http1.1`默认支持持久连接，`http1.1`通过使用持久连接来使多个`http`请求复用同一个`tcp`连接，避免使用非持久连接每次需要建立的时延
- **资源请求方面**：`http1.0`方面存在浪费带宽(客户端只是需要某个对象的一部分，但是服务器却将整个对象送来了，并且不支持断点续传功能)，`http1.1`在请求头引入`range`头域，它允许之请求资源的某个部分，即返回码是`206(partial content)`，便于开发者自由选择充分利用带宽

- **缓存方面**：在`http1.0`主要使用`header`里的`if-modified-since`、`expire`作为缓存标准判断，`http1.1`加入了`etag` `if-unmodified-since`、`if-match`、`if-none-match`等更多可供选择的缓存头来控制缓存策略
- `http1.1`新增**host字段**,用来指定服务器的域名，`http1.0`认为每台服务器都绑定一个唯一的`ip`，所以请求`url`没有传递主机名，但是随着技术发展，在一台物理机器可以存在多台虚拟主机，共享同一个`ip`地址，这样可以将请求发往同一台服务器的不同网站

- **1.1新增`put` `head` `options`等方法**

## `http1.1`和`2.0`的区别

- **二进制编码**：`2.0`是一个二进制协议，在1.1版本中，报文头信息必须是文本(ASCII编码)，数据可以是文本，也可以是二进制，2.0的头信息和数据体都是二进制，统称为帧，分为头信息帧和数据帧
- **多路复用**：2.0实现多路复用，复用tcp连接，但在一个连接里面客户端和服务端可以同时发送多个请求或响应，而且不用按照顺序一一发送，避免了**队头堵塞**的问题

- **数据流**：2.0采用了数据流的概念，因为前面的多路复用讲了，不用按顺序，所以同一个连接里面的数据包，可能属于不同的请求，所以要对数据包做标记，指出他属于哪一个请求。2.0将每个请求或回应的所有数据包称为一个数据流，都有一个独特的编号，数据包发送时候，都必须标记数据流id，来区分属于那个数据流
- **头信息压缩**：因为1.1协议不带状态，每次请求都得附上所有信息，请求很多字段都是重复的，比如cookies和user agent，一模一样的内容每次请求都得带上，浪费带宽和速度，2.0使用gzip或compress压缩再发出，而客户端和服务端同时维护一张头信息表，所有字段都会存入这张表中，生成一个索引号，以后不发送相同字段 只发索引号，可以提速

- **服务器推送**:2.0允许服务器未经请求主动向客户端发送资源，交服务器推送，提前给客户端推送必要的资源，减少延迟时间，需要注意的是2.0主动推送的是静态资源，跟ws以及使用的sse向客户端发送即时数据的推送是不同的

上面讲的队头阻塞是有HTTP基本的“请求 - 应答”模型导致的，http规定报文必须是一发一收，形成了先进先出的串行队列，队列请求没有优先级，只有入队的顺序，最前面的请求最先被处理，如果队首的请求因为处理的太慢了耽误了时间，那么后面的所有请求也得跟着等待，造成了队头阻塞



## https与http的区别

- https需要ca证书，http不用
- http是超文本传输协议，是明文传输，https是具有安全性的ssl加密传输

- http端口是80 https是443
- http是无状态的协议，https是具有ssl和http协议构建的可加密、身份认证的网络协议，比http安全



## GET方法对URL长度限制的原因

http不对get方法长度进行限制，其实这个限制是浏览器和服务器对url的限制，ie对url长度限制是2083字节(2k+35)，ie限制地最小，所以只要不超过2083就不会有问题

```javascript
GET的长度值 = URL（2083）- （你的Domain+Path）-2（2是get请求中?=两个字符的长度）
```



## 当在浏览器输入google.com回车之后会发生什么

1. **解析URL** 对URL进行解析，分析所用的传输协议和资源路径，如果不合法，就传递给搜索引擎，如果没问题，浏览器检查URL是否出现非法字符，若有则进行转义
2. **缓存判断** 判断资源是否存在缓存中，若在缓存且没有失效，就直接使用，否则向服务器发起新请求

1. **DNS解析** 获取URL中的域名的ip地址，会判断本地是否有该域名的ip地址的缓存，有则使用，没有向本地dns服务器请求，本地的dns服务器也会检查是否存在缓存，如果没有先向根域名服务器发起请求，获得负责的顶级域名服务器的地址再请求，然后获得负责的权威域名服务器的地址再请求，最终获得域名的ip地址，本地dns服务器再向返回给请求的用户(用户向本地dns服务器发起请求是递归请求，本地dns向各级域名服务器发起的请求是迭代请求)
2. **获取mac地址** 当浏览器得到ip地址时，数据传输还得知道mac地址，数据是从应用层下发到传输层，tcp会指定源端口号和目的端口号，然后下发给网络层，网络层将本地ip作为源地址，获取的ip作为目的ip，然后下发给数据链路层，数据链路层要加入通信双方的mac地址，本地mac作为源mac地址，目的mac地址分情况处理，通过ip地址与本地子网掩码相与，判断是否和请求主机处于同一个子网，如果在同一子网，用ARP协议获得目的主机的mac地址，如果不在，请求转发给网关，由他来转发，此时同样可以通过arp协议获得网关的mac地址，此时目的主机的mac地址为网关的地址

1. **TCP三次握手** 下面是 TCP 建立连接的三次握手的过程，首先客户端向服务器发送一个 SYN 连接请求报文段和一个随机序号，服务端接收到请求后向服务器端发送一个 SYN ACK报文段，确认连接请求，并且也向客户端发送一个随机序号。客户端接收服务器的确认应答后，进入连接建立的状态，同时向服务器也发送一个ACK 确认报文段，服务器端接收到确认后，也进入连接建立状态，此时双方的连接就建立起来了
2. **HTTPS握手** 通信还存在TLS的四次挥手 首先客户端向服务端发送协议的版本号、一个随机数和可以使用的加密方法，服务器收到后确认加密方法，想客户端发送一个随机数和自己的数字证书，客户端收到后检查数字证书是否有效，有效的话再生成一个随机数，使用证书的公钥对随机数加密 然后发给服务端，并且会提供一个前面所有内容的hash值给服务器检验，服务器接收后用私钥对数据解密，同时向客户端发送一个前面所有内容的hash值供客户端检验，双方这时有三个随机数，按之前的加密方法，使用这三个随机数生成一把密钥，以后双方传输数据时用这个密钥加密再传输

1. **返回数据** 当页面请求发到服务端，服务端会返回一个html文件作为响应，浏览器接到响应 对html进行解析，开始页面渲染
2. **页面渲染** 页面根据html文件构建dom树，根据css构建cssom树，如果遇到script 判断是否有defer或async，如果都没有会对页面的渲染堵塞，完了之后构建render tree，构建好了之后进行布局，最后使用浏览器的ui接口对页面进行绘制，最后页面显示出来

1. **TCP四次挥手** 最后一步是 TCP 断开连接的四次挥手过程。若客户端认为数据发送完成，则它需要向服务端发送连接释放请求。服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明客户端到服务端的连接已经释放，不再接收客户端发的数据了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。服务端如果此时还有没发完的数据会继续发送，完毕后会向客户端发送连接释放请求，然后服务端便进入 LAST-ACK 状态。客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态。该状态会持续 2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 CLOSED 状态。当服务端收到确认应答后，也便进入 CLOSED 状态。



## 对keep-alive的理解

http1.0默认每次请求/应答，客户端和服务端都会新建一个连接，完成之后断开连接，这是短连接

使用keep-alive使客户端到服务端的连接持续有效，当出现对服务器的后续请求时，可以避免建立或重新连接，这是长连接

使用方法：

- 1.0默认没有keep-alive，需要的话配置发送Connection: keep-alive
- 断开的话发送Connection: close

- 1.1版本默认保持长连接，数据传输完成的时候tcp连接不断开，等待同域名下继续使用这个通道传输数据，需要关闭就发送Connection: close

Keep-Alive的**建立过程**：

- 客户端向服务器在发送请求报文同时在首部添加发送Connection字段
- 服务器收到请求并处理 Connection字段

- 服务器回送Connection:Keep-Alive字段给客户端
- 客户端接收到Connection字段

- Keep-Alive连接建立成功

**服务端自动断开过程（也就是没有keep-alive）**：

- 客户端向服务器只是发送内容报文（不包含Connection字段）
- 服务器收到请求并处理

- 服务器返回客户端请求的资源并关闭连接
- 客户端接收资源，发现没有Connection字段，断开连接

**客户端请求断开连接过程**：

- 客户端向服务器发送Connection:close字段
- 服务器收到请求并处理connection字段

- 服务器回送响应资源并断开连接
- 客户端接收资源并断开连接

开启Keep-Alive的**优点：**

- 较少的CPU和内存的使⽤（由于同时打开的连接的减少了）；
- 允许请求和应答的HTTP管线化；

- 降低拥塞控制 （TCP连接减少了）；
- 减少了后续请求的延迟（⽆需再进⾏握⼿）；

- 报告错误⽆需关闭TCP连接

开启Keep-Alive的**缺点**：

- 长时间的Tcp连接容易导致系统资源无效占用，浪费系统资源。



## 页面有多张图片，http怎么加载

在http1，浏览器对一个域名下最大tcp连接数为6，所以会请求多次，可以用多域名部署解决，可以提高同时请求的数目，加快页面图片的获取速度

在http2中，支持多路复用，可以在一个tcp连接中发送多个http请求



## http2头部压缩算法如何实现

http2头部压缩是HPACK算法，在客户端和服务端两端建立“字典”，用索引号表示重复的字符串，采用哈夫曼编码压缩整数和字符串

- 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送；
- 首部表在HTTP/2的连接存续期内始终存在，由客户端和服务器共同渐进地更新；

- 每个新的首部键值对要么被追加到当前表的末尾，要么替换表中之前的值。



例如下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销。

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635822364675-42f16e63-20e0-4d6a-b009-56f6b594d9b5.webp)



## HTTP的请求报文是什么样的

由请求行 请求头部 空行 请求体组成

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635822978186-89f07016-c75a-41d6-bff8-d4e707573764.webp)

请求⾏包括：请求⽅法字段、URL字段、HTTP协议版本字段

请求头部:请求头部由关键字/值对组成，每⾏⼀对，关键字和值⽤英⽂冒号“:”分隔

- User-Agent：产⽣请求的浏览器类型。
- Accept：客户端可识别的内容类型列表。

- Host：请求的主机名，允许多个域名同处⼀个IP地址，即虚拟主机。

请求体: post put等请求携带的数据

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635823059461-e907fa45-f022-460a-af48-460b1951768f.webp)

## HTTP响应报文是什么样的

由响应行 响应头 空行 响应体

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635823125081-4a2bbb36-8feb-45e2-bdf4-555fe1bfd0d0.webp)

## http的优缺点

http是超文本传输协议，定义了客户端和服务端交换报文的格式和方式，默认使用80端口，使用tcp协议作为传输层协议，保证了数据传输的可靠

优点：

- 支持客户端/服务端
- 简单快捷 客户向服务器请求时 只需传送请求方法和路径 由于http协议简单 使得http服务器规模小，通信速度快

- 无连接 限制每次连接只处理一个请求，服务端处理完客户请求，客户收到应答就断开连接，可以节省传输时间
- 无状态 状态指的是通信上下文信息，缺少状态意味着如果后续处理需要前面的信息，就必须重传，导致每次连接传送的数据量增大，另一方面在服务器不需要之前的信息他的应答就比较快

- 灵活 http允许传输任意类型的数据对象，由content-type标记

缺点

- 无状态 服务器不会保存关于客户的任何消息
- 明文传输 报文采用文本形式 不安全

- 不安全 使用明文 内容易被窃听；不验证通信方身份，可能伪装；无法验证报文完整性，可能被篡改



## 说一下http3.0

基于UDP协议实现的类似于tcp多路复用的数据流，传输可靠性，称为QUIC协议

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635824059903-8c6ff160-4a35-4e94-9b9e-483edab5a3a2.webp)

1. 流量控制、传输可靠性：QUIC在udp基础上增加一层保证数据传输可靠性，提供了数据包重传 拥塞控制等
2. 集成TLS加密功能，减少花费的RTT数

1. 多路复用 同一个物理连接上可以有多个独立的逻辑数据流，实现数据流单独传输，解决tcp队头阻塞问题
2. 快速握手 基于udp，可以实现0-1个rtt来建立连接

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635824360759-2a170024-db77-4721-8860-605bc5ac29a8.webp)

## http性能怎么样

基于tcp/ip，使用**请求**和**应答**通信模式，所以性能来说这俩是关键

- 长连接 可以避免每次tcp连接三次握手花费
- http1.1 管道网络传输，就是一个tcp连接里面客户端可以发送多个请求

- 队头拥塞 http传输是一发一收 ，里面的任务放在一个任务队列中串行执行 一旦队首请求的太慢会阻塞后面请求的处理

- - 解决方法：
  - 并发连接 对于一个域名允许分配多个长连接，相当于增加了任务队列

- - 域名分片 将域名分出很多个二级域名，全都指向同样的一台服务器 能够并发的长连接数变多



# HTTPS协议

https协议是超文本传输安全协议，经由http进行通信，利用SSL/TLS来加密数据包，提供身份认证，保护交换数据的隐私与完整性

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635922602818-2032ac15-1789-47b6-97e3-94725327d9de.webp)



http协议采用明文传输，存在信息窃听，信息篡改，信息劫持的风险，而tls/ssl具有身份认证、信息加密、完整性校验的功能

他新增的安全层主要是对发起的http请求的数据进行加密操作和对收到的http内容进行解密操作



## 介绍一下TLS/SSL的工作原理

全称**安全传输层协议**, 是介于TCP和HTTP之间的一层安全协议

主要依赖 散列函数hash 对称加密 非对称加密，作用如下

- 基于散列函数验证信息的完整性
- 对称加密算法采用协商的密钥对数据加密

- 非对称加密实现对身份认证和密钥协商

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1635923500669-8aab3398-b88e-4b25-b76f-026bbd18a793.webp)



- 散列函数hash

- - 常用的散列函数有md5 sha1 sha256，特点为单向不可逆，对输入数据非常敏感，输出长度固定，任何数据的修改都会改变散列函数的结果，可以用于防止信息篡改并验证数据的完整性
  - 特点是在信息传输过程中，散列函数不能防止信息防篡改，由于传输的是明文，中间人可以修改信息后重新计算信息的摘要，所以需要对传输的信息和信息摘要进行加密

- 对称加密

- - 加密方法是双方使用同一个密钥对数据进行加密和解密，但是如何保证密钥传输的安全性，密钥可能在通过网络传输的过程中被其他人获取到
  - 常见的对称加密有AES-CBC DES 3DES AES-GCM，通讯方式为一对一

- - 对称加密的特点就是一对一，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和N个客户端通信则需要维持N个密码记录且不能修改密码

- 非对称加密

- - 拥有两个密钥，一个公钥一个私钥，公钥是公开的，私钥是保密的，用私钥加密数据，用公钥才能解密，用公钥加密，只有私钥才能解密，任何想通信的客户端都可以用公开的公钥进行加密，然后我们用私钥进行解密，保证数据的安全，但是缺点是加密过程很慢
  - 常见的非对称加密为RSA ECC DH ，客户端之间不能相互解密信息，只能和服务器进行加密通信，服务器可以实现一对多的通信，客户端可以用来验证掌握私钥的服务器的身份

- - 特点是信息一对多，服务器只需要维持一个私钥就能和多个客户端进行通信，但是服务器发送出去的信息能被所有客户端解密，计算复杂，加密速度慢

综上所述，tls/ssl的工作方式是客户端使用非对称加密与服务器进行通信，实现身份验证并协商对称加密使用的秘钥。对称加密算法采用协商秘钥对信息以及信息摘要进行加密通信，不同节点采用对称秘钥不同，从而保证信息只能通信双方获取。



## 什么是数字证书

为了避免中间人攻击，我们采用数字证书

使用一种hash算法对公钥和其他信息进行加密，生成一个信息摘要，然后让有公信力的认证中心(CA)用他的私钥对消息摘要加密，形成签名，最后将原始的信息和签名和在一起，称为数字证书，当接收方收到数字证书先根据原始信息用相同的hash算法生成摘要，使用公证处的公钥对数字证书的摘要进行解密，最后将解密的摘要和生成的摘要进行对比，可以发现得到的信息是否被篡改

最重要的是认证中心的可靠性，一般浏览器会内置一些顶层的认证中心的证书，相当我们信任了他

![img](https://cdn.nlark.com/yuque/0/2021/png/1190141/1635926471845-d37b38ad-e315-4ee9-b9f1-2416b61afce0.png)



## HTTPS的握手过程

1. 客户端向服务端发起请求，请求中包含使用的协议版本号，生成一个随机数，以及客户端支持的加密算法
2. 服务端收到请求，确认双方的加密方法、给出服务器的证书和服务器生成的随机数

1. 客户端确认服务端的证书有效后，生成一个新的随机数，并使用数字证书的公钥进行加密，再发给服务器，提供前面所有内容的hash，用来供服务器检验
2. 服务器用自己的私钥来解密发来的随机数，和前面提供的所有内容 hash 用来供客户端检验

1. 客户端和服务端根据约定的加密算法使用前面的三个随机数，生成对话密钥，以后的对话都用这个密钥进行加密信息



## HTTPS的特点

优点

- 可以认证用户和服务器 确保数据可以正确发送到客户端和服务端
- 可以加密传输 身份认证 防止数据在传输过程中被窃取 修改 确保数据安全性

- 不是绝对的安全，但是大幅增加中间人攻击的成本

缺点

- 需要做服务器和客户端双方的加密和解密处理，耗费更多服务器资源，过程复杂
- 握手阶段比较费时，增加页面的加载时间

- ssl证书收费 功能越强大费用越高
- https连接服务端资源占用高很多，支持访客稍多的网站需要投入更大成本

- ssl证书需要绑定ip，不能在同一ip上绑定多个域名



## https如何保证安全

先理解对称加密和非对称加密

- 对称加密为通信的双方都使用同一个密钥进行加解密，对称加密虽然简单性能好，但是无法解决首次把秘钥发给对方的问题，易被黑客拦截
- 非对称加密

- - 私钥 + 公钥 = 秘钥对
  - 私钥加密只能公钥解密 公钥加密只能私钥解密

- - 通信之前对方把自己的公钥先发给对方
  - 对方拿着公钥加密数据响应对方 等到数据传输到对方，对方再用自己的私钥进行解密

- - 安全性高 但是速度慢 影响性能

解决方案

结合两种加密方式 将对称加密的密钥通过非对称加密的公钥进行加密，然后发送出去，接收方通过自己的私钥进行解密，获得对称加密的密钥，然后双方可以使用对称加密进行沟通

但是如果中间人 把互发的公钥公钥换成自己的公钥就可以轻松解密通信双方发送的数据了

所以要有ca证书，防止中间人攻击

如果中间人篡改了证书，是不是身份证明无效了，这时候需要新的技术，数字签名

数字签名是ca自带的hash算法对证书的内容进行hash得到一个摘要，再用ca的密钥进行加密，最后组成数字签名，当别人收到证书的时候，用同样的hash算法再次生成摘要，用ca的公钥对数字签名解密，得到ca创建的消息摘要，然后对比可知有没有被篡改

# 状态码

## 状态码类别

| 1xx  | 信息性状态码     | 接收的请求正在处理           |
| ---- | ---------------- | ---------------------------- |
| 2xx  | 成功状态码       | 请求正常处理完毕             |
| 3xx  | 重定向状态码     | 需要进行附加操作才能完成请求 |
| 4xx  | 客户端错误状态码 | 服务器无法处理请求           |
| 5xx  | 服务端错误状态码 | 服务器处理请求出错           |

1. 2xx成功

1. 1. 200 OK 表示从客户端发的请求服务端正确处理了
   2. 204 No content 请求成功 响应报文不含实体的主体部分

1. 1. 205 reset content 请求成功 响应报文不含实体的主体部分 但与204不同的是要求请求方重置内容
   2. 206 partial content 进行范围请求

1. 3xx重定向

1. 1. 301 永久性重定向 表示资源已被分配了新的URL(当我们想换个域名时候；在搜素引擎搜索结果出现不带www的域名，而带www的域名没收录，就可以通过301告诉搜索引擎目标域名)
   2. 302 临时性重定向 表示资源临时被分配了新了URL（未登录的用户重定向到登录页面 访问404页面重定向到首页）

1. 1. 303 资源存在另一个URL 应该用get方法获取资源(一般用于上传文件后，返回的重定向到消息确认页面或者上传进度页面)
   2. 304 not modified 服务器允许访问资源 但是发送请求未满足的情况(浏览器存在缓存)

1. 1. 307 临时重定向 但是与302不同的是期望客户端保持请求方法不变向新的地址发出请求 （一般浏览器会自动由post -> get 但是307不会 还是post -> post）

1. 4xx 客户端错误

1. 1. 400 bad request 请求报文语法错误或格式不对
   2. 401 unauthorized 表示请求需要通过http认证的认证信息

1. 1. 403 forbidden 请求资源被服务器拒绝
   2. 404 not found 在服务器未找到请求的资源

1. 1. 405 method not allow 服务器禁止使用这种方法

1. 5xx服务器错误

1. 1. 500 server error 服务器请求执行时错误
   2. 501 服务器不支持当前请求的某个功能

1. 1. 503 service unavailable服务器暂时在超负载或停机维护(nginx限速)
   2. 504 gateway timeout 网关或代理服务器无法在规定时间获得响应(代码执行时间超过 或 死循环)



## 同样是重定向 302 303 307有什么区别

302是http1.0的协议状态码，在1.1后为了细化302，又分出了303和307

303明确了客户端应当采用get方法获得资源，会把post请求变成get请求进行重定向，307会遵照浏览器标准，不会冲post变成get



# DNS协议

## 介绍一下DNS协议是什么

DNS是域名系统的缩写，提供一种主机名到IP地址的转换服务，由分层的DNS服务器组成的分布式数据库，定义了主机如何查询这个分布式数据库的方式的应用协议

作用是将域名解析为IP地址，客户端向DNS服务器发送域名查询请求，DNS服务器告诉客户端他的web服务器的IP地址



## DNS同时使用tcp和udp协议吗

DNS占用53号端口，同时使用tcp和udp协议

1. 在区域传输的时候使用tcp协议

1. 1. 辅域名服务器会定时（一般三小时）向主域名查询了解数据是否右边，有变的话，会执行一次区域传送，进行数据同步，区域传送使用tcp，因为数据传送的数据量比一个请求应答的数据量多得多
   2. TCP是一种可靠连接 保证数据的准确性

1. 在域名解析的时候使用udp协议

1. 1. 客户端向dns查询域名，一般返回的内容不超过512字节，用udp传输即可，不经过三次握手，使得dns服务器负载更低，响应更快，理论上客户端向dns服务器查询域名的时候用tcp但是很多dns服务器配置时候只支持udp查询包



## 说一下DNS完整查询过程

- 首先在浏览器缓存中查找对应的IP地址，如果查到就直接返回，查不到就下一步
- 将请求发给本地dns服务器，在本地域名服务器查询，如果查到直接返回，差不到就下一步

- 本地dns服务器向根域名服务器发送请求，根域名服务器返回一个所查询域的顶级服务器地址
- 本地dns向顶级域名服务器发送请求，接收请求的服务器查询自己的缓存，如果有记录就返回查询结果，没有就返回下一级的权威域名服务器地址

- 本地dns向权威域名服务器请求，域名服务器返回对应结果
- 本地dns将结果保存在缓存中，便于下次使用

- 将结果返回给浏览器



## DNS的迭代查询和递归查询

递归查询指的是查询请求发送之后，域名服务器代为向下一级域名服务器发送请求，最后向用户返回结果，使用递归查询，用户只用发送一次查询

迭代查询是域名服务器返回单次查询的结果，需要用户自己请求下一级的服务器



一般我们向本地dns发送请求的都是递归查询，因为只发了一次就能返回最终的结果，而本地dns服务器向其他域名服务器采用的就是迭代查询，每一级域名服务器返回的结果之后，都由本地dns服务器自己进行下一级的查询



# 网络模型

## osi7层模型

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636097104815-686b255e-1b30-4016-8d5b-fa330f33c852.webp)

1. **应用层**

1. 1. 为计算机用户提供应用接口，为用户提供提供网络服务协议，如http https ftp等

1. **表示层**

1. 1. 用于对应用层数据的编码和转换功能，确保一个系统的应用程序发送的数据能被另一个系统应用层识别，可以使用base64对数据进行编解码，base64在表示层工作

1. **会话层**

1. 1. 负责建立、管理和终止表示层实体之间的通信会话

1. **传输层**

1. 1. 建立主机端到端的连接，传输层的作用就是为上层协议提供端到端的可靠和透明数据传输，包括差错控制和流量控制，tcp和udp就是在这一层

1. **网络层**

1. 1. 通过IP寻址建立两个节点的连接，通常就是我们说的IP协议层，我们可以理解网络层规定了数据包的传输路线，传输层规定了数据包的传输方式

1. **数据链路层**

1. 1. 将比特组合成字节，将字节组合成帧，使用链路层地址(以太网用mac地址)，并进行差错控制，我们可以理解为网络层是规划了数据包的传输路线，数据链路层就是传输路线，在数据链路层增加了差错控制

1. **物理层**

1. 1. 实际的信号通过物理层实现，通过物理截止传输比特流



OSI七层模型通信特点是对等通信，为了使数据分组从源传送到目的地，源端每一层都必须和目的端对等层进行通信，称为对等层通信，在每一层通信都使用本层自己的协议进行通信



## TCP/IP五层协议

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636100992582-f97ff282-7093-4a06-b367-1e864f993f2e.webp)

- 应用层

- - 直接为应用进程提供服务 http/ftp/smtp/dns

- 传输层

- - 主要有tcp和udp协议

- 网络层

- - 为两台主机提供通信服务 通过选择合适的路由将数据传递到目的主机

- 数据链路层

- - 将网络层交下来的IP数据包封装成帧，在链路两个相邻节点传送帧，每一帧都包含数据和必要的控制信息

- 物理层

- - 确保数据在各种物理媒介上传输

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636102343521-8e79d009-3524-403b-a625-b50b0a32c9d9.webp)



# TCP和UDP

## 介绍一下tcp和udp的概念

**UDP**全称是用户数据报协议，同tcp一样处理数据包，是一种无连接的协议，在OSI模型中它位于传输层，他不提供数据包分组、组装和不能对数据包进行排序，就是说当报文发送后不知道他是否安全完整到达

特点

- 无连接 

- - 不需要像tcp一样三次握手建立连接，想发送数据就开始发送，只搬运数据，不拆分也不拼接，在发送端只在数据加一个udp头标识，在接收端udp只去除IP报文头就传递给应用层，不拼接

- 有单播 多播 广播功能

- - 不只支持一对一，同样支持一对多 多对多

- 面向报文

- - 发送方udp对应用层传下来的报文，添加首部就向下交付给IP层，不合并不拆分

- 不可靠性

- - 体现在无连接上，通信不需要建立连接，不备份数据，不关心对方是否正确收到数据
  - 网络环境时好时坏，但是udp没有拥塞控制，会一直以很顶速度发送数据，导致了在网络不好的时候会丢包，但是在某些实时性的场景(电话会议)使用的就是UDP而不是TCP

- 头部开销小，传输报文高效

- - 包含两个十六位的端口号，分别是源端口(可选)和目标端口
  - 整个数据报文的长度

- - 整个数据报文的检验和IPV4，该字段用于发现头部信息和数据的错误
  - 所以头部开销小，只有8字节， tcp至少20字节



TCP是传输控制协议，是面向连接的，可靠的，基于字节流的传输层通信协议

特点：

- 面向连接

- - 需要进行三次握手

- 仅支持单播传输

- - 每条tcp传输连接只有两个端点，只能进行点对点数据传输

- 面向字节流

- - 不保留报文边界的情况下以字节流的方式进行传输

- 可靠传输

- - 判断丢包、误码是靠tcp的段编号以及确认号，tcp为了保证报文传输的可靠性，给每个包一个序号，同时序号保证了传送到接收端的实体的包按序接收，接收实体会返回一个确认号，如果发送端实体在往返时延（rtt）内未确认，那么对应数据会被重传

- 提供拥塞控制

- - 当网络出现拥塞，tcp能减少向网络注入数据的速率和数量

- 提供全双工通信

- - tcp在两端都设有缓存，用来临时存放双向通信的数据，当然，TCP可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于MSS）



## TCP和UDP的区别

|              | UDP                                 | TCP                                               |
| ------------ | ----------------------------------- | ------------------------------------------------- |
| 是否连接     | 无连接                              | 面向连接                                          |
| 是否可靠     | 不可靠传输 不使用流量控制和拥塞控制 | 可靠传输(数据顺序和正确性) 使用流量控制和拥塞控制 |
| 连接对象个数 | 支持一对一 一对多 多对一            | 只能一对一                                        |
| 传输方式     | 面向报文                            | 面向字节流                                        |
| 首部开销     | 首部开销小 仅8字节                  | 首部最小20字节 最大60字节                         |
| 使用场景     | 实时应用 视频会议 直播              | 可靠传输的应用 文件传输                           |



## TCP和UDP的使用场景

TCP效率要求比较低，但是要求准度比较高，因为传输过程中要对数据进行确认、重发、排序等，例如文件传输(准确度高，可以牺牲速度)，接收邮件，远程登录

UDP效率要求高，但是要求准确度比较低，例如qq聊天，在线视频，网络语音电话(即时通讯 速度要求比较高，偶尔断续无所谓，不能使用重发机制)，广播通信(广播，多播)



## UDP为什么不可靠

- UDP在传输数据之前不需要先建立连接，远地主机的运输层在接收到UDP报文后，不需要确认，提供不可靠交付。总结就以下四点：
- 不保证消息交付：不确认，不重传，无超时

- 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞
- 不跟踪连接状态：不必建立连接或重启状态机

- 不进行拥塞控制：不内置客户端或网络反馈机制

## TCP的重传机制

由于TCP的下层（网络层）可能出现**丢失、重复或失序**的情况，TCP提供可靠数据传输服务。

为保证数据传输的正确性，TCP会重传其认为已丢失（包括报文中的比特错误）的包。

TCP使用两套独立的机制来完成重传，一是**基于时间**，二是**基于确认信息**。

TCP在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的ACK确认报文，则对该报文进行重传，在达到一定次数还没有成功时放弃并发送一个复位信号。

## TCP的拥塞控制机制

TCP的拥塞控制机制主要是以下四种机制：

- 慢启动（慢开始）
- 拥塞避免

- 快速重传
- 快速恢复

**（1）慢启动（慢开始）**

- 在开始发送的时候设置cwnd = 1（cwnd指的是拥塞窗口）
- 思路：开始的时候不要发送大量数据，而是先测试一下网络的拥塞程度，由小到大增加拥塞窗口的大小。

- 为了防止cwnd增长过大引起网络拥塞，设置一个慢开始门限(ssthresh 状态变量) 

- - 当cnwd < ssthresh，使用慢开始算法
  - 当cnwd = ssthresh，既可使用慢开始算法，也可以使用拥塞避免算法

- - 当cnwd > ssthresh，使用拥塞避免算法

**（2）拥塞避免**

- 拥塞避免未必能够完全避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性增长，使网络不容易出现阻塞。
- 思路： 让拥塞窗口cwnd缓慢的增大，即每经过一个返回时间RTT就把发送方的拥塞控制窗口加一

- 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。如图所示: ![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636293975468-43012d7a-3e66-4a51-93c9-af092274f845.webp) 其中，判断网络出现拥塞的根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理。

**（3）快速重传**

- 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认(为的是使发送方及早知道有报文段没有到达对方)。发送方只要连续收到三个重复确认就立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
- 由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量

**（4）快速恢复**

- 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。
- 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。 ![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636293975489-1debf772-7865-4b20-83df-4365e065332e.webp)



## TCP的流量控制

一般来说，流量控制就是为了让发送方发送数据的速度不要太快，要让接收方来得及接收。

TCP采用大小可变的**滑动窗口**进行流量控制，窗口大小的单位是字节。这里说的窗口大小其实就是每次传输的数据大小。

- 当一个连接建立时，连接的每一端分配一个缓冲区来保存输入的数据，并将缓冲区的大小发送给另一端。
- 当数据到达时，接收方发送确认，其中包含了自己剩余的缓冲区大小。（剩余的缓冲区空间的大小被称为窗口，指出窗口大小的通知称为窗口通告 。接收方在发送的每一确认中都含有一个窗口通告。）

- 如果接收方应用程序读数据的速度能够与数据到达的速度一样快，接收方将在每一确认中发送一个正的窗口通告。
- 如果发送方操作的速度快于接收方，接收到的数据最终将充满接收方的缓冲区，导致接收方通告一个零窗口 。发送方收到一个零窗口通告时，必须停止发送，直到接收方重新通告一个正的窗口。



## TCP的可靠传输

TCP 的可靠传输机制是基于连续 ARQ 协议和滑动窗口协议的。

TCP 协议在发送方维持了一个发送窗口，发送窗口以前的报文段是已经发送并确认了的报文段，发送窗口中包含了已经发送但 未确认的报文段和允许发送但还未发送的报文段，发送窗口以后的报文段是缓存中还不允许发送的报文段。当发送方向接收方发 送报文时，会依次发送窗口内的所有报文段，并且设置一个定时器，这个定时器可以理解为是最早发送但未收到确认的报文段。 

如果在定时器的时间内收到某一个报文段的确认回答，则滑动窗口，将窗口的首部向后滑动到确认报文段的后一个位置，此时如 果还有已发送但没有确认的报文段，则重新设置定时器，如果没有了则关闭定时器。如果定时器超时，则重新发送所有已经发送 但还未收到确认的报文段，并将超时的间隔设置为以前的两倍。

当发送方收到接收方的三个冗余的确认应答后，这是一种指示， 说明该报文段以后的报文段很有可能发生丢失了，那么发送方会启用快速重传的机制，就是当前定时器结束前，发送所有的已发 送但确认的报文段。

接收方使用的是累计确认的机制，对于所有按序到达的报文段，接收方返回一个报文段的肯定回答。如果收到了一个乱序的报文 段，那么接方会直接丢弃，并返回一个最近的按序到达的报文段的肯定回答。使用累计确认保证了返回的确认号之前的报文段都 已经按序到达了，所以发送窗口可以移动到已确认报文段的后面。

发送窗口的大小是变化的，它是由接收窗口剩余大小和网络中拥塞程度来决定的，TCP 就是通过控制发送窗口的长度来控制报文 段的发送速率。

但是 TCP 协议并不完全和滑动窗口协议相同，因为许多的 TCP 实现会将失序的报文段给缓存起来，并且发生重传时，只会重 传一个报文段，因此 TCP 协议的可靠传输机制更像是窗口滑动协议和选择重传协议的一个混合体。



## TCP的三次握手和四次挥手

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636295566186-e28d8182-b0ee-43dd-b59b-80d48eaaf980.webp)

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。

刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态。

- 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN，此时客户端处于 SYN_SEND 状态。

首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段不能携带数据，但要消耗掉一个序号。

- 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。

在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y

- 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。

确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。

**那为什么要三次握手呢？两次不行吗？**

- 为了确认双方的接收能力和发送能力都正常
- 如果是用两次握手，则会出现下面这种情况：

如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

**简单来说就是以下三步：**

- **第一次握手：** 客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入 SYN-SENT 状态。
- **第二次握手：** 服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯初始序号，发送完成后便进入 SYN-RECEIVED 状态。

- **第三次握手：** 当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入 ESTABLISHED 状态，服务端收到这个应答后也进入 ESTABLISHED 状态，此时连接建立成功。

TCP 三次握手的建立连接的过程就是相互确认初始序号的过程，告诉对方，什么样序号的报文段能够被正确接收。 第三次握手的作用是客户端对服务器端的初始序号的确认。如果只使用两次握手，那么服务器就没有办法知道自己的序号是否 已被确认。同时这样也是为了防止失效的请求报文段被服务器接收，而出现错误的情况。

（2）四次挥手

![img](https://cdn.nlark.com/yuque/0/2021/webp/1190141/1636295600194-df812818-dc3c-469b-aa42-24c6528fcbe4.webp) 刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：

- 第一次挥手： 客户端会发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。

即发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。

- 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。

即服务端收到连接释放报文段后即发出确认报文段（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。

- 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。

即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。

- 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。

**那为什么需要四次挥手呢？**

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送，故需要四次挥手。

**简单来说就是以下四步：**

- **第一次挥手：** 若客户端认为数据发送完成，则它需要向服务端发送连接释放请求。
- **第二次挥手**：服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明客户端到服务端的连接已经释放，不再接收客户端发的数据了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。

- **第三次挥手**：服务端如果此时还有没发完的数据会继续发送，完毕后会向客户端发送连接释放请求，然后服务端便进入 LAST-ACK 状态。
- **第四次挥手：** 客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态。该状态会持续 2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 CLOSED 状态。当服务端收到确认应答后，也便进入 CLOSED 状态。

TCP 使用四次挥手的原因是因为 TCP 的连接是全双工的，所以需要双方分别释放到对方的连接，单独一方的连接释放，只代 表不能再向对方发送数据，连接处于的是半释放的状态。

最后一次挥手中，客户端会等待一段时间再关闭的原因，是为了防止发送给服务器的确认报文段丢失或者出错，从而导致服务器 端不能正常关闭。



## TCP的粘包是什么意思 如何处理

默认情况下, TCP 连接会启⽤延迟传送算法 (Nagle 算法), 在数据发送之前缓存他们. 如果短时间有多个数据发送, 会缓冲到⼀起作⼀次发送 (缓冲⼤⼩⻅ socket.bufferSize ), 这样可以减少 IO 消耗提⾼性能.

如果是传输⽂件的话, 那么根本不⽤处理粘包的问题, 来⼀个包拼⼀个包就好了。但是如果是多条消息, 或者是别的⽤途的数据那么就需要处理粘包.

下面看⼀个例⼦, 连续调⽤两次 send 分别发送两段数据 data1 和 data2, 在接收端有以下⼏种常⻅的情况: A. 先接收到 data1, 然后接收到 data2 . B. 先接收到 data1 的部分数据, 然后接收到 data1 余下的部分以及 data2 的全部. C. 先接收到了 data1 的全部数据和 data2 的部分数据, 然后接收到了 data2 的余下的数据. D. ⼀次性接收到了 data1 和 data2 的全部数据.

其中的 BCD 就是我们常⻅的粘包的情况. ⽽对于处理粘包的问题, 常⻅的解决⽅案有:

- **多次发送之前间隔⼀个等待时间**：只需要等上⼀段时间再进⾏下⼀次 send 就好, 适⽤于交互频率特别低的场景. 缺点也很明显, 对于⽐较频繁的场景⽽⾔传输效率实在太低，不过⼏乎不⽤做什么处理.
- **关闭 Nagle 算法**：关闭 Nagle 算法, 在 Node.js 中你可以通过 socket.setNoDelay() ⽅法来关闭 Nagle 算法, 让每⼀次 send 都不缓冲直接发送。该⽅法⽐较适⽤于每次发送的数据都⽐较⼤ (但不是⽂件那么⼤), 并且频率不是特别⾼的场景。如果是每次发送的数据量⽐较⼩, 并且频率特别⾼的, 关闭 Nagle 纯属⾃废武功。另外, 该⽅法不适⽤于⽹络较差的情况, 因为 Nagle 算法是在服务端进⾏的包合并情况, 但是如果短时间内客户端的⽹络情况不好, 或者应⽤层由于某些原因不能及时将 TCP 的数据 recv, 就会造成多个包在客户端缓冲从⽽粘包的情况。 (如果是在稳定的机房内部通信那么这个概率是⽐较⼩可以选择忽略的)

- **进⾏封包/拆包：** 封包/拆包是⽬前业内常⻅的解决⽅案了。即给每个数据包在发送之前, 于其前/后放⼀些有特征的数据, 然后收到数据的时 候根据特征数据分割出来各个数据包。

## 为什么UDP不会粘包

- TCP协议是⾯向流的协议，UDP是⾯向消息的协议。UDP段都是⼀条消息，应⽤程序必须以消息为单位提取数据，不能⼀次提取任意字节的数据
- UDP具有保护消息边界，在每个UDP包中就有了消息头（消息来源地址，端⼝等信息），这样对于接收端来说就容易进⾏区分处理了。传输协议把数据当作⼀条独⽴的消息在⽹上传输，接收端只能接收独⽴的消息。接收端⼀次只能接收发送端发出的⼀个数据包,如果⼀次接受数据的⼤⼩⼩于发送端⼀次发送的数据⼤⼩，就会丢失⼀部分数据，即使丢失，接受端也不会分两次去接收。

# WebSocket

## 介绍一下websocket

WebSocket是HTML5提供的一种浏览器与服务器进行**全双工通讯**的网络技术，属于应用层协议。它基于TCP传输协议，并复用HTTP的握手通道。浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接， 并进行双向数据传输。

WebSocket 的出现就解决了半双工通信的弊端。它最大的特点是：**服务器可以向客户端主动推动消息，客户端也可以主动向服务器推送消息。**

**WebSocket原理**：客户端向 WebSocket 服务器通知（notify）一个带有所有接收者ID（recipients IDs）的事件（event），服务器接收后立即通知所有活跃的（active）客户端，只有ID在接收者ID序列中的客户端才会处理这个事件。

**WebSocket 特点的如下：**

- 支持双向通信，实时性更强
- 可以发送文本，也可以发送二进制数据

- 建立在TCP协议之上，服务端的实现比较容易
- 数据格式比较轻量，性能开销小，通信高效

- 没有同源限制，客户端可以与任意服务器通信
- 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL

- 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。

**Websocket的使用方法如下：**

在客户端中：

```javascript
// 在index.html中直接写WebSocket，设置服务端的端口号为 9999
let ws = new WebSocket('ws://localhost:9999');
// 在客户端与服务端建立连接后触发
ws.onopen = function() {
    console.log("Connection open."); 
    ws.send('hello');
};
// 在服务端给客户端发来消息的时候触发
ws.onmessage = function(res) {
    console.log(res);       // 打印的是MessageEvent对象
    console.log(res.data);  // 打印的是收到的消息
};
// 在客户端与服务端建立关闭后触发
ws.onclose = function(evt) {
  console.log("Connection closed.");
}; 
```

### 即时通讯的实现：短轮询、长轮询、SSE 和 WebSocket 间的区别？

短轮询和长轮询的目的都是用于实现客户端和服务器端的一个即时通讯。

**短轮询的基本思路：** 浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化。这种方式的优点是比较简单，易于理解。缺点是这种方式由于需要不断的建立 http 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。

**长轮询的基本思路：** 首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。长轮询和短轮询比起来，它的优点是明显减少了很多不必要的 http 请求次数，相比之下节约了资源。长轮询的缺点在于，连接挂起也会导致资源的浪费。

**SSE 的基本思想：** 服务器使用流信息向服务器推送信息。严格地说，http 协议无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息。也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。SSE 就是利用这种机制，使用流信息向浏览器推送信息。它基于 http 协议，目前除了 IE/Edge，其他浏览器都支持。它相对于前面两种方式来说，不需要建立过多的 http 请求，相比之下节约了资源。

**WebSocket** 是 HTML5 定义的一个新协议议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。使用 WebSocket 协议的缺点是在服务器端的配置比较复杂。WebSocket 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息，而 SSE 的方式是单向通信的，只能由服务器端向客户端推送信息，如果客户端需要发送信息就是属于下一个 http 请求了。

**上面的四个通信协议，前三个都是基于HTTP协议的。**

对于这四种即使通信协议，从性能的角度来看： **WebSocket > 长连接（SEE） > 长轮询 > 短轮询** 但是，我们如果考虑浏览器的兼容性问题，顺序就恰恰相反了： **短轮询 > 长轮询 > 长连接（SEE） > WebSocket** 所以，还是要根据具体的使用场景来判断使用哪种方式。